filter(Species == "WBNU") %>%
mutate(LoggerDate = paste0(Logger, Date))
#Run Gaussian Mixture Model. Note that this is a stochastic process so end result can be slightly different each time.
dowoflocks=gmmevents(dat.dowo$Timestamp, dat.dowo$RFID, dat.dowo$LoggerDate)
wbnuflocks=gmmevents(dat.wbnu$Timestamp, dat.wbnu$RFID, dat.wbnu$LoggerDate)
saveRDS(dowoflocks, "conspecificDOWOflocks_v2.rds")
saveRDS(wbnuflocks, "conspecificWBNUflocks_v2.rds")
dowogmm1=readRDS("conspecificDOWOflocks.rds")
dowogmm2=readRDS("conspecificDOWOflocks_v2.rds")
str(dowogmm1)
dowogmm1$metadata
load("all_visits.dat")
head(all_visits)
all_visits %>% mutate(Timestamp = as.numeric(Datetime))
###
library(tidyverse)
all_visits %>% mutate(Timestamp = as.numeric(Datetime))
all_visits = all_visits %>% mutate(Timestamp = as.numeric(Datetime))
head(all_visits)
all_visits = all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
select(Datetime, Timestamp)
head(all_visits)
all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
select(Datetime, Timestamp)
dowogmm1$metadata
tail(dowogmm1$metadata)
all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
select(Logger,Datetime, Timestamp)
all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
mutate(LoggerDate = paste0(Logger, Date)) %>%
select(Logger,Datetime, Timestamp)
head(all_visits)
head(all_visits)
load("all_visits.dat")
all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
mutate(LoggerDate = paste0(Logger, Date)) %>%
select(Logger,Datetime, Timestamp)
all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
mutate(LoggerDate = paste0(Logger, Date)) %>%
select(LoggerDate,Datetime, Timestamp)
tail(dowogmm1$metadata)
all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
mutate(LoggerDate = paste0(Logger, Date)) %>%
select(LoggerDate,Datetime, Timestamp, Location)
load("all_visits.dat")
all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
mutate(LoggerDate = paste0(Logger, Date)) %>%
select(LoggerDate,Datetime, Timestamp, Location)
tail(dowogmm1$metadata)
all_visits %>%
mutate(Timestamp = as.numeric(Datetime)) %>%
mutate(LoggerDate = paste0(Logger, Date)) %>%
select(LoggerDate,Datetime, Timestamp)
#import Gaussian Mixture Model Results
dowo_gmm=readRDS("conspecificDOWOflocks_v2.rds")
wbnu_gmm=readRDS("conspecificWBNUflocks_v2.rds")
#extract group-by-individual matrices
dowo_gbi=dowo_gmm$gbi
wbnu_gbi=wbnu_gmm$gbi
#make networks
dowo_net=graph_from_adjacency_matrix(get_network(dowo_gbi), mode="undirected", weighted=T)
wbnu_net=graph_from_adjacency_matrix(get_network(wbnu_gbi), mode="undirected", weighted=T)
#### Analysis code, Part 1 for Madsen, Vander Meiden & Shizuka: Social partners and temperature jointly affect morning foraging activity of small birds in winter#####
#generates network plots for Figure 1
#measures assortment and social differentiation
library(asnipe)
library(igraph)
library(assortnet)
#make networks
dowo_net=graph_from_adjacency_matrix(get_network(dowo_gbi), mode="undirected", weighted=T)
wbnu_net=graph_from_adjacency_matrix(get_network(wbnu_gbi), mode="undirected", weighted=T)
#import individual attributes data & match up with network vertices
indivs=read.csv("RFID_Records_fixed.csv")
V(dowo_net)$sex=indivs[match(V(dowo_net)$name, indivs$RFID),"Sex"]
V(wbnu_net)$sex=indivs[match(V(wbnu_net)$name, indivs$RFID),"Sex"]
V(dowo_net)$age=indivs[match(V(dowo_net)$name, indivs$RFID),"Age"]
#make network plots for Figure 1
sex_color=data.frame(sex=c("F", "M", "U"), color=c("yellow", "purple", "white"))
plot(dowo_net, vertex.color=sex_color[match(V(dowo_net)$sex, sex_color$sex), "color"], vertex.label="", edge.width=E(dowo_net)$weight*30)
plot(wbnu_net, vertex.color=sex_color[match(V(wbnu_net)$sex, sex_color$sex), "color"], vertex.label="", edge.width=E(wbnu_net)$weight*30)
#assortment by sex for DOWO
sexassort_dowo=assortment.discrete(as_adj(dowo_net, sparse=F, attr="weight"), V(dowo_net)$sex, SE=T)
sexassort_dowo$r
random_sex_dowo=lapply(1:1000, function(x) sample(V(dowo_net)$sex, length(V(dowo_net)$sex), replace=F))
assort_rand_dowo=sapply(random_sex_dowo, function(x) assortment.discrete(as_adj(dowo_net, sparse=F, attr="weight"), x, SE=F)$r)
p_assort_dowo=length(which(assort_rand_dowo<sexassort_dowo$r))/1001
ci_assort_rand_dowo=quantile(assort_rand_dowo, probs = c(0.025, 0.925))
p_assort_dowo
ci_assort_rand_dowo
#assortment by sex for WBNU
sexassort_wbnu=assortment.discrete(as_adj(wbnu_net, attr="weight", sparse=F), V(wbnu_net)$sex, SE=T)
sexassort_wbnu$r
#do node permutations and generate p-value and confidence interval for WBNU
random_sex_wbnu=lapply(1:1000, function(x) sample(V(wbnu_net)$sex, length(V(wbnu_net)$sex), replace=F))
assort_rand_wbnu=sapply(random_sex_wbnu, function(x) assortment.discrete(as_adj(wbnu_net, attr="weight", sparse=F), x, SE=F)$r)
p_assort_wbnu=length(which(assort_rand_wbnu<sexassort_wbnu$r))/1001
ci_assort_rand_wbnu=quantile(assort_rand_wbnu, probs = c(0.025, 0.925))
p_assort_wbnu
ci_assort_rand_wbnu
## daily visits per individual
dv <- all_visits %>%
filter(Date < "2019-03-11" & Date > "2019-01-25") %>%
group_by(RFID, Date) %>%
summarise(dailyvisits = n())
## mean daily visits per individual
ref <- dv %>%
group_by(RFID) %>%
summarise(mdv = mean(dailyvisits)) %>%
ungroup()
## sd of daily visits
dvsd <- sd(dv$dailyvisits)
## build the df
mat_ddm <- cast(dv, Date ~ RFID, value = "dailyvisits")
mat_ddm[is.na(mat_ddm)] <- 0
mat <- mat_ddm[2:46]/dvsd
myvec <- (ref$mdv[match(names(mat_ddm[2:45]), ref$RFID)])/dvsd
mat_final <- mat[1] - myvec[1]
for(i in 2:44){
mat_temp <- mat[i] - myvec[i]
mat_final <- cbind(mat_final, mat_temp)
}
#mat_final <- cbind(mat_ddm$Date, mat_final)
### Similarity Matrix
## how similar are individuals' daily visitation z-scores?
require(proxy)
simmat <- as.matrix(simil(mat_final, by_rows = FALSE))
#########Spatial Overlap Matrix
### summarise number of visits at each feeder for each bird
vis <- all_visits %>%
group_by(Logger, RFID) %>%
summarise(logvis = n()) %>%
ungroup()
### reshape data frame and calculate proportion of visits at each feeder
logsums <- cast(vis, Logger ~ RFID, value = "logvis")
logsums[is.na(logsums)] <- 0
y = colSums(logsums)
fin <- as.data.frame(mapply("/", logsums[-1], y))
### make correlation/similarity matrix
require(proxy)
logmat <- as.matrix(simil(fin, by_rows = FALSE))
dowosim=simmat[match(rownames(dowoadj), rownames(simmat)), match(rownames(dowoadj), rownames(simmat))] #sort the activity correlation matrix so rows/columns match adjacency matrix
dowospat=logmat[match(rownames(dowoadj), rownames(logmat)), match(rownames(dowoadj), rownames(logmat))] #sort spatial correlation matrix so rows/columns match adjacency matrix.
#same for WBNU
wbnusim=simmat[match(rownames(wbnuadj), rownames(simmat)), match(rownames(wbnuadj), rownames(simmat))]
wbnuspat=logmat[match(rownames(wbnuadj), rownames(logmat)), match(rownames(wbnuadj), rownames(logmat))]
#MRQAP
#now, normalize all matrix values so that minimum number = 0 and maximum number = 1
normalize_matrix=function(m){
(m-min(m, na.rm=T))/(max(m, na.rm=T)-min(m, na.rm=T))
}
dowosim.norm=normalize_matrix(dowosim)
dowoadj.norm=normalize_matrix(dowoadj)
dowospat.norm=normalize_matrix(dowospat)
dowo.mrqap.norm=mrqap.dsp(dowosim.norm~dowoadj.norm+dowospat.norm) #same test, but now with normalized values. The results are the same but the coefficient is different.
dowo.mrqap.norm
require(reshape)
require(proxy)
## daily visits per individual
dv <- all_visits %>%
filter(Date < "2019-03-11" & Date > "2019-01-25") %>%
group_by(RFID, Date) %>%
summarise(dailyvisits = n())
## mean daily visits per individual
ref <- dv %>%
group_by(RFID) %>%
summarise(mdv = mean(dailyvisits)) %>%
ungroup()
## sd of daily visits
dvsd <- sd(dv$dailyvisits)
## build the df
mat_ddm <- cast(dv, Date ~ RFID, value = "dailyvisits")
mat_ddm[is.na(mat_ddm)] <- 0
mat <- mat_ddm[2:46]/dvsd
myvec <- (ref$mdv[match(names(mat_ddm[2:45]), ref$RFID)])/dvsd
mat_final <- mat[1] - myvec[1]
for(i in 2:44){
mat_temp <- mat[i] - myvec[i]
mat_final <- cbind(mat_final, mat_temp)
}
#mat_final <- cbind(mat_ddm$Date, mat_final)
### Similarity Matrix
## how similar are individuals' daily visitation z-scores?
simmat <- as.matrix(simil(mat_final, by_rows = FALSE))
#########Spatial Overlap Matrix
### summarise number of visits at each feeder for each bird
vis <- all_visits %>%
group_by(Logger, RFID) %>%
summarise(logvis = n()) %>%
ungroup()
### reshape data frame and calculate proportion of visits at each feeder
logsums <- cast(vis, Logger ~ RFID, value = "logvis")
logsums[is.na(logsums)] <- 0
y = colSums(logsums)
fin <- as.data.frame(mapply("/", logsums[-1], y))
### make correlation/similarity matrix
require(proxy)
logmat <- as.matrix(simil(fin, by_rows = FALSE))
dowosim=simmat[match(rownames(dowoadj), rownames(simmat)), match(rownames(dowoadj), rownames(simmat))] #sort the activity correlation matrix so rows/columns match adjacency matrix
dowospat=logmat[match(rownames(dowoadj), rownames(logmat)), match(rownames(dowoadj), rownames(logmat))] #sort spatial correlation matrix so rows/columns match adjacency matrix.
#same for WBNU
wbnusim=simmat[match(rownames(wbnuadj), rownames(simmat)), match(rownames(wbnuadj), rownames(simmat))]
wbnuspat=logmat[match(rownames(wbnuadj), rownames(logmat)), match(rownames(wbnuadj), rownames(logmat))]
#MRQAP
#now, normalize all matrix values so that minimum number = 0 and maximum number = 1
normalize_matrix=function(m){
(m-min(m, na.rm=T))/(max(m, na.rm=T)-min(m, na.rm=T))
}
dowosim.norm=normalize_matrix(dowosim)
dowoadj.norm=normalize_matrix(dowoadj)
dowospat.norm=normalize_matrix(dowospat)
dowo.mrqap.norm=mrqap.dsp(dowosim.norm~dowoadj.norm+dowospat.norm) #same test, but now with normalized values. The results are the same but the coefficient is different.
dowo.mrqap.norm
###MRQAP
dowoadj=get_network(gbi_dowo)
wbnuadj=get_network(gbi_wbnu)
###MRQAP
dowoadj=get_network(dowo_gbi)
wbnuadj=get_network(wbnu_gbi)
## daily visits per individual
dv <- all_visits %>%
filter(Date < "2019-03-11" & Date > "2019-01-25") %>%
group_by(RFID, Date) %>%
summarise(dailyvisits = n())
## mean daily visits per individual
ref <- dv %>%
group_by(RFID) %>%
summarise(mdv = mean(dailyvisits)) %>%
ungroup()
## sd of daily visits
dvsd <- sd(dv$dailyvisits)
## build the df
mat_ddm <- cast(dv, Date ~ RFID, value = "dailyvisits")
mat_ddm[is.na(mat_ddm)] <- 0
mat <- mat_ddm[2:46]/dvsd
myvec <- (ref$mdv[match(names(mat_ddm[2:45]), ref$RFID)])/dvsd
mat_final <- mat[1] - myvec[1]
for(i in 2:44){
mat_temp <- mat[i] - myvec[i]
mat_final <- cbind(mat_final, mat_temp)
}
#mat_final <- cbind(mat_ddm$Date, mat_final)
### Similarity Matrix
## how similar are individuals' daily visitation z-scores?
simmat <- as.matrix(simil(mat_final, by_rows = FALSE))
#########Spatial Overlap Matrix
### summarise number of visits at each feeder for each bird
vis <- all_visits %>%
group_by(Logger, RFID) %>%
summarise(logvis = n()) %>%
ungroup()
### reshape data frame and calculate proportion of visits at each feeder
logsums <- cast(vis, Logger ~ RFID, value = "logvis")
logsums[is.na(logsums)] <- 0
y = colSums(logsums)
fin <- as.data.frame(mapply("/", logsums[-1], y))
### make correlation/similarity matrix
require(proxy)
logmat <- as.matrix(simil(fin, by_rows = FALSE))
dowosim=simmat[match(rownames(dowoadj), rownames(simmat)), match(rownames(dowoadj), rownames(simmat))] #sort the activity correlation matrix so rows/columns match adjacency matrix
dowospat=logmat[match(rownames(dowoadj), rownames(logmat)), match(rownames(dowoadj), rownames(logmat))] #sort spatial correlation matrix so rows/columns match adjacency matrix.
#same for WBNU
wbnusim=simmat[match(rownames(wbnuadj), rownames(simmat)), match(rownames(wbnuadj), rownames(simmat))]
wbnuspat=logmat[match(rownames(wbnuadj), rownames(logmat)), match(rownames(wbnuadj), rownames(logmat))]
#MRQAP
#now, normalize all matrix values so that minimum number = 0 and maximum number = 1
normalize_matrix=function(m){
(m-min(m, na.rm=T))/(max(m, na.rm=T)-min(m, na.rm=T))
}
dowosim.norm=normalize_matrix(dowosim)
dowoadj.norm=normalize_matrix(dowoadj)
dowospat.norm=normalize_matrix(dowospat)
dowo.mrqap.norm=mrqap.dsp(dowosim.norm~dowoadj.norm+dowospat.norm) #same test, but now with normalized values. The results are the same but the coefficient is different.
dowo.mrqap.norm
###
###WBNU
wbnu.ids=rownames(wbnuadj)
wbnugbi=gbi_wbnu[,which(colnames(gbi_wbnu)%in%wbnu.ids)] #get gbi with only wbnus
wbnugbi.filt=wbnugbi[which(rowSums(wbnugbi)>0),] #remove groups that no wbnus belong to.
wbnumetadata.filt=gmmWBNU$metadata[which(rowSums(wbnugbi)>0),] #remove the same groups in the group metadata
#using the filtered metadata, we can extract the feeder & date of the group. This will be useful when we constrain the permutation by day
wbnu.locations=as.numeric(as.factor(substr(wbnumetadata.filt$Location, start=1, stop=8)))
wbnu.days=as.numeric(as.factor(substr(wbnumetadata.filt$Location, start=10, stop=13)))
#store the results of MRQAP with empirical network
wbnusim.norm=normalize_matrix(wbnusim)
wbnuadj.norm=normalize_matrix(wbnuadj)
wbnuspat.norm=normalize_matrix(wbnuspat)
emp.mod.wbnu=mrqap.dsp(wbnusim.norm~wbnuadj.norm+wbnuspat.norm)
emp.coef.wbnu=emp.mod.wbnu$coefficients[2]
emp.mod.wbnu
emp.coef.wbnu
wbnugbi=wbnu[_gbi,which(colnames(gbi_wbnu)%in%wbnu.ids)] #get gbi with only wbnus
wbnugbi=wbnu_gbi,which(colnames(gbi_wbnu)%in%wbnu.ids)] #get gbi with only wbnus
wbnugbi=wbnu_gbi[which(colnames(gbi_wbnu)%in%wbnu.ids)] #get gbi with only wbnus
wbnugbi=wbnu_gbi[which(colnames(wbnu_gbi)%in%wbnu.ids)] #get gbi with only wbnus
wbnugbi.filt=wbnugbi[which(rowSums(wbnugbi)>0),] #remove groups that no wbnus belong to.
wbnugbi
wbnu.ids
wbnu_gbi
which(colnames(wbnu_gbi)%in%wbnu.ids)
wbnugbi=wbnu_gbi[,which(colnames(wbnu_gbi)%in%wbnu.ids)] #get gbi with only wbnus
wbnugbi.filt=wbnugbi[which(rowSums(wbnugbi)>0),] #remove groups that no wbnus belong to.
wbnumetadata.filt=gmmWBNU$metadata[which(rowSums(wbnugbi)>0),] #remove the same groups in the group metadata
wbnumetadata.filt=wbnu_gmm$metadata[which(rowSums(wbnugbi)>0),] #remove the same groups in the group metadata
#using the filtered metadata, we can extract the feeder & date of the group. This will be useful when we constrain the permutation by day
wbnu.locations=as.numeric(as.factor(substr(wbnumetadata.filt$Location, start=1, stop=8)))
wbnu.days=as.numeric(as.factor(substr(wbnumetadata.filt$Location, start=10, stop=13)))
#store the results of MRQAP with empirical network
wbnusim.norm=normalize_matrix(wbnusim)
wbnuadj.norm=normalize_matrix(wbnuadj)
wbnuspat.norm=normalize_matrix(wbnuspat)
emp.mod.wbnu=mrqap.dsp(wbnusim.norm~wbnuadj.norm+wbnuspat.norm)
emp.coef.wbnu=emp.mod.wbnu$coefficients[2]
emp.mod.wbnu
emp.coef.wbnu
##dowo
dowovisits=mat_final[,which(colnames(mat_final)%in%rownames(dowoadj))]
dowovisits.mat=as.matrix(dowovisits)
dowoadj.bin=dowoadj
dowoadj.bin[which(dowoadj.bin>0)]=1
colSums(dowoadj.bin[1,]*t(dowovisits.mat), na.rm=T)
dowoadj.norm.row=t(apply(dowoadj, 1, function(x) x/sum(x, na.rm=T)))
dowo.friend.activity=apply(dowoadj.norm.row, 1, function(x) colSums(x*t(dowovisits.mat), na.rm=T))
dowo.friend.activity=as.data.frame(dowo.friend.activity)
dowo.friend.activity
library(lme4)
library(lmerTest)
library(MuMIn)
dowo.a= dowovisits.dat %>% gather("ID", "z_score", -Date, -nightlows)
dowo.friend.activity$Date=weather.use$Date
dowo.friend.activity$nightlows=weather.use$nightlows
dowo.b = dowo.friend.activity %>% gather("ID", "z_score_friends", -Date, -nightlows)
dowo.final.dat=merge(dowo.a,dowo.b)
dowomod=lmer(z_score~scale(nightlows)*scale(z_score_friends)+(1|ID), data=dowo.final.dat)
summary(dowomod)
r.squaredGLMM(dowomod)
dowovisits.dat=as.data.frame(dowovisits)
dowovisits.dat$Date=weather.use$Date
dowovisits.dat$nightlows=weather.use$nightlows
dowo.a= dowovisits.dat %>% gather("ID", "z_score", -Date, -nightlows)
dowo.friend.activity$Date=weather.use$Date
dowo.friend.activity$nightlows=weather.use$nightlows
dowo.b = dowo.friend.activity %>% gather("ID", "z_score_friends", -Date, -nightlows)
dowo.final.dat=merge(dowo.a,dowo.b)
dowomod=lmer(z_score~scale(nightlows)*scale(z_score_friends)+(1|ID), data=dowo.final.dat)
summary(dowomod)
colnames(mat_final)
##dowo
dowovisits=mat_final[,which(colnames(mat_final)%in%rownames(dowoadj))]
dowovisits.mat=as.matrix(dowovisits)
dowoadj.bin=dowoadj
dowoadj.bin[which(dowoadj.bin>0)]=1
colSums(dowoadj.bin[1,]*t(dowovisits.mat), na.rm=T)
dowoadj.norm.row=t(apply(dowoadj, 1, function(x) x/sum(x, na.rm=T)))
dowo.friend.activity=apply(dowoadj.norm.row, 1, function(x) colSums(x*t(dowovisits.mat), na.rm=T))
dowo.friend.activity=as.data.frame(dowo.friend.activity)
dowo.friend.activity
dowovisits.dat=as.data.frame(dowovisits)
dowovisits.dat$Date=weather.use$Date
load("all_visits.dat")
load("weather.dat")
demo=read.csv("RFID_Records_fixed.csv")
all_visits
weather$Date <- as.Date(weather$Date, format = "%m/%d/%Y")
weather.use <- weather %>%
mutate(Hour = hour(datetime)) %>%
filter(Hour >= 19 | Hour <= 4) %>%
mutate(Lagdate = ifelse(Hour <= 4, paste0(lag(Date)), paste0(Date))) %>%
group_by(Date) %>%
summarize(nightlows = min(Temp_C)) %>%
ungroup() %>%
filter(Date>"2019-01-26"&Date<"2019-03-10")
weather %>%
mutate(Hour = hour(datetime))
weather
hour(datetime)
library(lubridate)
weather$Date <- as.Date(weather$Date, format = "%m/%d/%Y")
weather.use <- weather %>%
mutate(Hour = hour(datetime)) %>%
filter(Hour >= 19 | Hour <= 4) %>%
mutate(Lagdate = ifelse(Hour <= 4, paste0(lag(Date)), paste0(Date))) %>%
group_by(Date) %>%
summarize(nightlows = min(Temp_C)) %>%
ungroup() %>%
filter(Date>"2019-01-26"&Date<"2019-03-10")
#weather
dowovisits.dat=as.data.frame(dowovisits)
dowovisits.dat$Date=weather.use$Date
dowovisits.dat$nightlows=weather.use$nightlows
dowo.a= dowovisits.dat %>% gather("ID", "z_score", -Date, -nightlows)
dowo.friend.activity$Date=weather.use$Date
dowo.friend.activity$nightlows=weather.use$nightlows
dowo.b = dowo.friend.activity %>% gather("ID", "z_score_friends", -Date, -nightlows)
dowo.final.dat=merge(dowo.a,dowo.b)
dowomod=lmer(z_score~scale(nightlows)*scale(z_score_friends)+(1|ID), data=dowo.final.dat)
summary(dowomod)
r.squaredGLMM(dowomod)
dowomod=lmer(z_score~scale(nightlows)*scale(z_score_friends), data=dowo.final.dat)
dowomod=lmer(z_score~scale(nightlows)*scale(z_score_friends)+(1|ID), data=dowo.final.dat)
summary(dowomod)
r.squaredGLMM(dowomod)
dowomod=lmer(z_score~scale(nightlows)+scale(z_score_friends)+(1|ID), data=dowo.final.dat)
summary(dowomod)
r.squaredGLMM(dowomod)
##wbnu
wbnuvisits=mat_final[,which(colnames(mat_final)%in%rownames(wbnuadj))]
wbnuvisits.mat=as.matrix(wbnuvisits)
wbnuadj.trim=wbnuadj[which(rownames(wbnuadj)%in%colnames(mat_final)),which(rownames(wbnuadj)%in%colnames(mat_final))]
colSums(wbnuadj.trim[1,]*t(wbnuvisits.mat), na.rm=T)
wbnuadj.norm.row=t(apply(wbnuadj.trim, 1, function(x) x/sum(x, na.rm=T)))
wbnu.friend.activity=apply(wbnuadj.norm.row, 1, function(x) colSums(x*t(wbnuvisits.mat), na.rm=T))
wbnu.friend.activity=as.data.frame(wbnu.friend.activity)
wbnu.friend.activity
wbnuvisits.dat=as.data.frame(wbnuvisits)
wbnuvisits.dat$Date=weather.use$Date
wbnuvisits.dat$nightlows=weather.use$nightlows
wbnu.a= wbnuvisits.dat %>% gather("ID", "z_score", -Date, -nightlows)
wbnu.friend.activity$Date=weather.use$Date
wbnu.friend.activity$nightlows=weather.use$nightlows
wbnu.b = wbnu.friend.activity %>% gather("ID", "z_score_friends", -Date, -nightlows)
wbnu.final.dat=merge(wbnu.a,wbnu.b)
wbnumod=lmer(z_score~scale(nightlows)*scale(z_score_friends)+(1|ID), data=wbnu.final.dat)
summary(wbnumod)
wbnumod=lmer(z_score~scale(nightlows)+scale(z_score_friends)+(1|ID), data=wbnu.final.dat)
summary(wbnumod)
r.squaredGLMM(wbnumod)
## This time with single-species networks
library(asnipe)
library(igraph)
#import files
gmmDOWO=readRDS("conspecificDOWOflocks.rds") #import gmm results file. Will need this for permuting group-by-individual matrices.
gmmWBNU=readRDS("conspecificWBNUflocks.rds") #import gmm results file. Will need this for permuting group-by-individual matrices.
gbi_dowo=gmmDOWO$gbi
gbi_wbnu=gmmWBNU$gbi
dowoadj=get_network(gbi_dowo)
wbnuadj=get_network(gbi_wbnu)
diag(dowoadj)=NA #make diagonal of adjacency matrices NA so we don't count these when normalizing values later.
diag(wbnuadj)=NA #make diagonal of adjacency matrices NA so we don't count these when normalizing values later.
simmat=as.matrix(read.csv("simmat.csv", row.names = 1, check.names = F)) #import correlation matrix of daily activity (Z-scores)
logmat=as.matrix(read.csv("logmat.csv", row.names = 1, check.names = F)) #import correlation matrix of proportional feeder use
dowosim=simmat[match(rownames(dowoadj), rownames(simmat)), match(rownames(dowoadj), rownames(simmat))] #sort the activity correlation matrix so rows/columns match adjacency matrix
dowospat=logmat[match(rownames(dowoadj), rownames(logmat)), match(rownames(dowoadj), rownames(logmat))] #sort spatial correlation matrix so rows/columns match adjacency matrix.
#same for WBNU
wbnusim=simmat[match(rownames(wbnuadj), rownames(simmat)), match(rownames(wbnuadj), rownames(simmat))]
wbnuspat=logmat[match(rownames(wbnuadj), rownames(logmat)), match(rownames(wbnuadj), rownames(logmat))]
#MRQAP-without normalizing values.
mrqap.dsp(dowosim~dowoadj+dowospat) #using activity similarity as the response variable and network + logger similarity as a covariates. This is raw numbers, not normalized.
mrqap.dsp(wbnusim~wbnuadj+wbnuspat)
# #now, normalize all matrix values so that minimum number = 0 and maximum number = 1
normalize_matrix=function(m){
(m-min(m, na.rm=T))/(max(m, na.rm=T)-min(m, na.rm=T))
}
dowosim.norm=normalize_matrix(dowosim)
dowoadj.norm=normalize_matrix(dowoadj)
dowospat.norm=normalize_matrix(dowospat)
dowo.mrqap.norm=mrqap.dsp(dowosim.norm~dowoadj.norm+dowospat.norm) #same test, but now with normalized values. The results are the same but the coefficient is different.
dowo.mrqap.norm
str(dowo.mrqap.norm)
mean(dowo.mrqap.norm$fitted.values)
###dowo permutations
dowo.ids=rownames(dowoadj)
dowogbi=gbi_dowo[,which(colnames(gbi_dowo)%in%dowo.ids)] #get gbi with only DOWOs
dowogbi.filt=dowogbi[which(rowSums(dowogbi)>0),] #remove groups that no DOWOs belong to.
dowometadata.filt=gmmDOWO$metadata[which(rowSums(dowogbi)>0),] #remove the same groups in the group metadata
#using the filtered metadata, we can extract the feeder & date of the group. This will be useful when we constrain the permutation by day
dowo.locations=as.numeric(as.factor(substr(dowometadata.filt$Location, start=1, stop=8)))
dowo.days=as.numeric(as.factor(substr(dowometadata.filt$Location, start=10, stop=13)))
#Run 10,000 group membership permutations with swaps constrained by date (but not feeder)
# dowoperm=network_permutation(dowogbi.filt, data_format="GBI", permutation=10000, association_matrix = dowoadj, locations=dowo.locations, days=dowo.days, within_day=TRUE, within_location=FALSE)
#
# plot(apply(dowoperm, 1, max), type="l", ylab="maximum edge weight", xlab="# swaps", main="DOWO permutations")
#store the results of MRQAP with empirical network
emp.mod.dowo=mrqap.dsp(dowosim.norm~dowoadj.norm+dowospat.norm)
emp.coef.dowo=emp.mod.dowo$coefficients[2]
#now do 1000 sets of swaps and store results
normalize_matrix=function(m){
(m-min(m, na.rm=T))/(max(m, na.rm=T)-min(m, na.rm=T))
}
### DOWO with parallel processing!
library(foreach)
library(parallel)
library(doParallel)
times=10
n.cores=detectCores()
system.time({
registerDoParallel(n.cores)
dowo.results.parallel=foreach(i = 1:times) %dopar% as.matrix(network_swap(dowogbi.filt, data_format="GBI", swaps=10000, association_matrix = dowoadj, locations=dowo.locations, days=dowo.days, within_day=TRUE, within_location=FALSE)$Association_index)
})
stopImplicitCluster()
dowoperm.adjs=dowo.results.parallel
dowoperm.mrqap.coefs=vector(length=times)
for(j in 1:times){
adj=dowoperm.adjs[[j]]
diag(adj)=NA
adj.norm=normalize_matrix(adj)
dowoperm.mrqap.coefs[j]=mrqap.dsp(dowosim.norm~adj.norm+dowospat.norm, randomisations=1)$coefficients[2]
}
dowoperm.mrqap.coefs
save(dowoperm.adjs, dowoperm.mrqap.coefs, p.dowo, ci.dowo, file="dowo_results_20201001_rdat")
p.dowo=(length(which(dowoperm.mrqap.coefs>=emp.coef.dowo))+1)/(times+1)
p.dowo #p-value
ci.dowo=quantile(dowoperm.mrqap.coefs, probs=c(0.025, 0.975))
ci.dowo #confidence interval of null model -- this likely will not overlap the empirical coefficient value
save(dowoperm.adjs, dowoperm.mrqap.coefs, p.dowo, ci.dowo, file="dowo_results_20201001_rdat")
